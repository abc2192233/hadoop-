## hdfs(Hadoop Distributed File System)

### 背景和一些设计思路
1. 硬件错误的自愈方案，在集群中某些硬件错误导致文件无法访问的故障检测和自动恢复
2. 流式数据访问，批处理数据的吞吐量POSIX语义修改
3. 大规模数据集，文件大小一般在GB到TB间，关于文件传输时对于整体带宽传输的优化
4. 简单的一致性模型，关于“一次访问多次读取”类型的文件访问模型时，一个文件经过创建写入关闭之后不需要再改变，简化数据一致性模型，提高访问吞吐量上界
5. “移动计算比移动数据更划算”，在数据达到海量级别时，通过传输计算程序比传输计算数据效率更高，能降低网络阻塞的影响
6. 异构软硬件平台间的可移植性，方便平台的扩容和移植
7. NameNode和DataNode，hdfs采用master/slave架构，1个NameNode对应多个DataNode
![image](frame_img/hdfsarchitecture.gif)
<p align="center">hdfs architecture</p>

### 文件系统的名字空间（namespace）
HDFS支持传统的层次型文件组织结构，用户或者应用程序可以创建目录，然后将文件保存至目录中。当前hdfs不支持用户磁盘配额和访问权限控制，也不支持硬链接和软连接。
NameNode复制维护文件系统的namespace，任何文件系统的namespace或属性的修改都会被NameNode记录，应用程序可以设置hdfs保存的文件副本数目

### 数据复制
hdfs可支持跨机器的存储超大文件，将每个文件存储成一系列的数据块，除了最后一块，所有的数据块大小都是相同的。并且每个数据块都会有副本，并且hdfs中的文件都是一次性写入的，并且严格要求任何时候都只能有一个写入者NameNode全权管理数据块的复制，它周期性的从每个DataNode接收心跳信号和块状态检测
![image](frame_img/hdfsdatanodes.gif)
<p align="center">hdfsdatanodes</p>

### 副本存放：最开始的第一步
副本存放是分布式文件系统可靠性和性能的关键，优化副本存放策略是hdfs区分于其他大部分分布式文件系统的重要特性，需要大量的调优和经验的积累。 同时通过机架感知技术（rack-aware）的策略改进数据的可靠性，如将数据块的不同副本存放不同机架上以防止在整个机架失效时数据的丢失

### 副本选择
为了降低整体带宽的消耗的延迟，hdfs会尽量让读取程序获取离它最近的副本，如果一个hdfs集群跨越多个数据中心，那么客户端也会优先读取本地数据中心的副本

### 安全模式
NameNode在启动后会进入安全模式的特殊状态，处于安全模式的NameNode是不会进行数据块的复制并且从所有DataNode接收心跳信号和块状态报告，块状态报告包括DataNode的所有数据块列表，并且每个数据块都有一个指定的最小副本数，当NameNode检测确认某个数据块的副本数量达到了最小值，那么该数据块就会被认为是安全的，在一定比例的数据块被确认是安全状态之后（加上一个额外时间差 30s），NameNode将退出安全模式状态，接下来它会确定还有哪些数据块的副本数没有达到指定数目，并将这些数据块复制到其他DataNode

### 文件系统元数据的持久化
NameNode保持着HDFS的namespace，对于任何对文件系统元数据产生修改的操作，都会由EditLog的事物日志所记录。NameNode在内存中保存着整个文件系统的namespace和文件数据块映射（Blockmap）的映像。当NameNode启动时，从硬盘读取EditLog和FsImage，将所有EditLog中的事务作用于内存中的FsImage，并将这个新版本的FsImage从内存保存到本地硬盘上，然后删除旧的EditLog，这个过程称为一个检查点（checkpoint）。在当前实现中，检查点只发生在NameNode启动时，在之后版本将实现周期性的检查点

### 通讯协议
所有的HDFS通讯协议都是建立在TCP/IP协议之上的，客户端通过ClientProtocol协议与NameNode交互，而DataNode则是使用DataNodeProtocol协议与NameNode交互。在设计上，NameNode不会主动发起RPC，而是响应来自客户端或者DataNode的RPC请求。

## 健壮性
HDFS的主要目标就是即使在出错的情况下也要保住数据存储的可靠性，常见的三种错误情况：NameNode出错，DataNode出错和网络割裂

### 磁盘数据错误，心跳机制和重新复制
每个DataNode都会周期性的向NameNode发送心跳信号。网络割裂可能会导致DataNode与NameNode失联，NameNode会通过心跳信号的缺失来检测这一情况，并将近期不在发送心跳信号的DataNode节点标记为宕机，并且会启动复制操作将宕机节点的数据块副本分发给其他节点

### 集群均衡
hdfs架构支持数据均衡策略。如果某个DataNode节点上的空闲值低于临界值，按照均衡策略系统会自动的将数据从这个DataNode移动到其他空闲的DataNode

### 数据完整性
当某个DataNode获取的数据块可能是损坏的，hdfs客户端软件会对hdfs文件内容的校验和（checksum）检测。当客户端创建一个新的hdfs文件，会计算文件每个数据块的校验和，并将校验和作为一个单独的隐藏文件保存在同一个hdfs命名空间下。当客户端获取文件内容后，会校验从DataNode获取的数据跟相应的校验文件进行匹配，如果不匹配则选择从其他客户端获取文件副本数据块

### 元数据磁盘错误
FsImage和EditLog是hdfs的核心数据结构，如果这些文件损坏，整个hdfs实例都将失效，所有NameNode可配置为支持维护多个FsImage和EditLog的副本，任何对FsImage或者EditLog的修改，都会同步到它们的副本上。这种多副本的同步操作可能会降低NameNode每秒处理namespace的数量，然而这个代价时是可接受的，因为hdfs的应用是数据密集的，它们也非元数据密集的。当NameNode重启是，会选取最近的完整的EditLog和FsImage来使用

### 快照
目前还不支持

### 数据组织

1. 数据块，HDFS支持文件“一次写入多次读取”的语义，一个典型的数据块大小是64MB
2. Staging，客户端创建文件请求时会先在本地创建一个缓存文件，然后应用程序的写操作会被透明的重定向到这个临时文件。当这个临时文件的累计大小超过一个数据块的大小时，客户端才会联系NameNode，NameNode将文件名插入文件系统的层次结构中，并分配一个数据块给它，然后返回DataNode的标识符和目标数据块给客户端，接着客户端才将这块数据从本地的临时文件上传到指定DataNode，当传输完成是，NameNode才会将文件创建操作提交至日志里进行存储。对于一些流式文件的传输，如果不采用客户端缓存的方案会对网络速度和造成较大影响
3. 流水线复制，当第一个数据块复制开始时，会每4KB的接收数据，会传输该部分到副本节点，副本1节点以此类推至副本n

### 存储空间回收
1. 文件删除和恢复，当用户删除某个文件时，实际上会将这个文件重命名转移到/trash目录，只要文件还在该目录中就可以迅速的被恢复，存放时间是可配置的
2. 减少副本系数，当一个文件的副本系数被减小之后，NameNode会选择的将过剩的副本删除